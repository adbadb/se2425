Конспект Лекции
Эволюция Хранилищ Данных - От Data Lake к Data Lakehouse

1. Хранилища данных

Мы уже рассматривали традиционные ХД и методологии их проектирования. Вспомним их ключевые особенности.
- Schema-on-Write. Схема данных (структура таблиц, типы данных) определяется заранее. Данные проходят от извлечения из источника до загрузки в уже подготовленное хранилище по процессу ETL, где они очищаются, трансформируются и валидируются в соответствии с предопределенной схемой.
- Данные структурированы. Преимущественно работает с реляционными данными, организованными в таблицы (схемы Звезда и Снежинка - это особые реляционные схемы).
- ACID Транзакции. Обеспечивается целостность и сохранность данных, особенно при конкурентном доступе.
- Приспособлены к выполнению сложных аналитических запросов (OLAP). Используются особые индексы, предагрегация, материализованные представления, оптимизированные схемы данных.
- Высокое качество данных обеспечивается проверками и преобразованиями при ETL.
- Высокая стоимость, как с точки зрения инфраструктуры (специализированное оборудование или облачные сервисы), так и с точки зрения управления и разработки ETL-процессов. Масштабирование может быть дорогим и сложным
- Низкая гибкость. Добавление новых источников данных или изменение схемы требует значительных усилий и времени (перепроектирование ETL, изменение схемы таблиц). Не подходит для экспериментов с сырыми данными. Некоторые подходы (Data Vault, Anchor Modeling) нацелены на увеличение гибкости, но за счет сложности разработки и поддержки.
- Типичные сценарии использования: отчеты, дашборды, исторический анализ структурированных данных.
- Невозможно или очень дорого хранить все данные (особенно сырые и неструктурированные). Не подходит для новых типов аналитики и клиентов, таких как машинное обучение, которое часто требует доступа к детальным, сырым данным в различных форматах.

2. Data Lake (Озеро Данных)

Data Lake – это централизованное хранилище, позволяющее хранить все данные (структурированные, полуструктурированные, неструктурированные) в любом масштабе и в их исходном формате. Обычно строится на основе распределенной файловой системы (HDFS) или дешевого и масштабируемого объектного хранилища (чаще всего S3-совместимого).
Ключевые характеристики озера данных.
- Schema-on-Read. Данные загружаются "как есть" просто в файлы. Схему данных выявляем во время чтения (например, разбирая текстовые строки содержания). 
- Любые форматы данных: Parquet, ORC, CSV, JSON, XML, изображения, аудио, видео, лог-файлы и т.д.
- Диски для HDFS или S3 гораздо дешевле дисков и другого железа для СУБД хранилища данных.
- Высокая гибкость. Новые данные можно загружать быстро без предварительного анализа и преобразований. Аналитики данных гораздо быстрее получают доступ к свежим данных.
- Практически неограниченная масштабируемость по объему данных и пропускной способности.
- Разнообразие рабочих нагрузок: Подходит для Data Science, машинного обучения, разных видов анализа данных, где важен доступ к исходным детальным данным.
- Сценарии использования: хранение всех корпоративных данных для потенциального будущего использования, платформы для ML/AI, хранение логов, архивирование данных.

Озеро данных без должного управления и контроля часто превращается в "болото" - Data Swamp.
- Распределенные файловые системы/объектные хранилища не поддерживают ACID. Читатели могут видеть неполные или несогласованные данные.
- Сложность внесения изменений (UPDATE/DELETE). HDFS и S3 не разрешают изменять загруженные файлы. Файл нужно выкачать, изменить на клиенте и закачать обратно, удалив старый файл. 
- Отсутствие централизованного управления схемой и качеством данных. Данные могут не иметь описания, иметь несовместимые форматы или низкое качество. 
- Производительность при точечных запросах или аналитических запросах, требующих фильтрации и агрегации на больших объемах, может быть низкой.
- В озере может храниться огромное количество файлов и папок, и без надлежащих инструментов управления метаданными и каталогов, найти нужные данные и понять их смысл становится большой проблемой.

3. Data Lakehouse

Data Lakehouse (DLH) – это новая архитектура, которая стремится объединить лучшие черты Data Lake (масштабируемость, гибкость, стоимость, поддержка всех типов данных) и Data Warehouse (структура, ACID-транзакции, управление схемой, производительность для структурированных запросов). Data Lakehouse строится *на основе* Data Lake (HDFS, S3), добавляя к нему уровень управления транзакционными метаданными (Transactional Metadata Layer) или уровень табличных форматов  (Table Format).
Уровень табличных форматов - это ключевой компонент DLH. Он отслеживает, какие файлы данных входят в каждую версию таблицы, обеспечивает ACID-транзакции, управление схемой, поддержку обновлений/удалений и другие функции. Основные реализации:  Delta Lake, Apache Iceberg, Apache Hudi.
Уровень метаданных:
- Обеспечивает атомарность операций записи и изоляцию для читателей. Каждое изменение данных записывается как атомарный коммит.
- Позволяет определять и принудительно применять схему таблицы, а также безопасно ее изменять (добавлять/удалять столбцы) без переписывания всей истории данных.
- Выполняет операции UPDATE/DELETE отдельных записей либо без необходимости перезаписывать большие объемы данных, либо делая это эффективно в фоновом режиме.
- Хранит метаданные в файлах (статистика, минимальные/макисмальные значения), что позволяет движкам запросов пропускать ненужные файлы при чтении.
- Благодаря отслеживанию версий состояния таблицы, можно в некоторых пределах запрашивать данные на предыдущий момент времени или откатываться к предыдущим версиям
- Данные хранятся в открытых форматах (Parquet, ORC), а уровень метаданных часто основан на открытых стандартах или проектах. Это позволяет избежать привязки к конкретному вендору и использовать разные вычислительные движки поверх одних и тех же данных.

4. Уровень транзакционных метаданных / форматов таблиц

Это технологии, которые являются сердцем Data Lakehouse, добавляя структуру, надежность и управляемость к коллекциям файлов в Data Lake. Рассмотрим три наиболее популярные: Apache Iceberg, Apache Hudi и Delta Lake.

4.1. Apache Iceberg

Разработан в Netflix для решения проблем масштабирования и надежности таблиц на основе Hive Metastore. Сейчас является проектом Apache Software Foundation, а а большинство авторов работает в Databrics.
Iceberg определяет, как отслеживать набор файлов данных (например, Parquet), которые составляют таблицу. В отличие от традиционного подхода Hive Metastore, где таблице соответствует папка, а партиции – подпапки, Iceberg хранит списки файлов данных в служебных файлах - манифестах. 
- Каждое изменение данных в таблице (коммит) создает новый снимок ее состояния. Снимок – это согласованное представление таблицы на определенный момент времени. Каждый снимок состоит из одного или нескольких манифестов. Манифест – это список файлов данных, которые входят в этот снимок. В манифестах также хранится статистика по файлам (например, минимальное и максимальное значение по столбцам), что позволяет движкам читать только нужные файлы данных.
- Поддерживает безопасное добавление, удаление, переименование и изменение порядка столбцов без необходимости перезаписывать существующие файлы данных.
- Позволяет изменять стратегию партиционирования таблицы со временем, не трогая старые файлы и разделы. Движок знает, как читать данные из старых и новых партиций.
- Обеспечивает скрытое партиционирование: пользователям не нужно в запросах указывать параметры разделов. Движки использует метаданные Iceberg для фильтрации по партициям автоматически, что упрощает запросы.
- Хорошая поддержка в движках запросов: Spark, Flink, Trino, Presto, Hive, Impala, Dremio, StarRocks и других. 

4.2. Apache Hudi (Hierarchical Unified Data Ingestion)

Изначально разработан в Uber для управления большими, постоянно меняющимися наборами данных (например, данные о поездках). Сейчас проект Apache Software Foundation.
Hudi предоставляет абстракцию управляемой таблицы поверх HDFS/S3, оптимизированную для инкрементальной обработки данных и эффективного управления UPDATE/DELETE.
- Отслеживает все операции (коммиты, компакции, очистки) как "мгновения" (instants) на временной шкале. Каждое мгновение имеет тип, статус и timestamp.
- Два основных способа организации данных и обработки изменений: Copy-on-Write (COW) и Merge-On-Read (MOR).
COW: при обновлении или удалении записей, файлы Parquet (базовые файлы), содержащие эти записи, полностью перезаписываются с внесенными изменениями. Эффективно, если чтение происходит гораздо чаще, чем запись/обновление.
MOR: Обновления и удаления записываются в отдельные файлы - журналы изменений (delta logs). Базовые файлы (обычно Parquet) остаются неизменными до операции слияния. При чтении данные из базовых файлов и соответствующих журналов изменений объединяются "на лету". Оптимален для рабочих нагрузок с частыми и небольшими обновлениями/удалениями, но чтение может быть медленнее из-за необходимости слияния.
- ACID транзакции реализованы на уровне коммитов.
- Встроенные механизмы для Upsert/Delete.
- Возможность читать только те данные, которые были изменены или добавлены с момента последнего коммита. Это очень полезно для построения инкрементальных конвейеров данных.
- Возможность читать версии данных на указанный момент времени  (Time Travel).
- Автоматическое слияние (compaction) базовых файлов с журналами изменений.
- Хорошая поддержка со стороны движков запросов, особенно в Spark и Flink, а также в Hive, Trino, Presto, Impala.

4.3. Delta Lake

Разработан и поддерживается компанией Databricks (основатели Apache Spark). В 2019 году ядро Delta Lake было передано в Linux Foundation как открытый проект, в то время как Databricks продолжает разрабатывать коммерческие расширения.
- Журнал Транзакций (DeltaLog) - центральный элемент Delta Lake. Это упорядоченный, атомарный, основанный на файлах журнал всех коммитов (изменений транзакций), выполненных в таблице. Каждый коммит записывается как новый файл в подпапке _delta_log в корневой директории delta-таблицы. Этот лог отслеживает список файлов данных (Parquet), которые составляют текущую версию таблицы, а также метаданные операций.
- Обеспечивает ACID транзакции благодаря атомарности записей в DeltaLog и использованию оптимистичного управления конкурентным доступом.
- По умолчанию Delta Lake блокирует запись данных в таблицу, если их схема несовместима с текущей схемой таблицы. Позволяет добавлять столбцы к таблице.
- Предоставляет мощную и эффективную команду MERGE INTO для выполнения операций слияния данных, которые могут включать вставку новых строк, обновление существующих и удаление строк.
- Благодаря журналу транзакций, можно легко получать доступ к предыдущим версиям таблицы, используя номер версии или временную метку. 
- Использует метаданные, собранные в DeltaLog (например, минимальные/максимальные значения по столбцам в каждом файле), для пропуска чтения файлов, которые не содержат данных, соответствующих условиям запроса.
- Z-ordering: Техника многомерной кластеризации данных в файлах Parquet, которая улучшает производительность запросов с предикатами по нескольким столбцам.
- Выполняет слияние (Compaction) мелких файлов Parquet в более крупные, что улучшает производительность чтения.
- Тесная интеграция со Spark (особенно в Databricks), также поддерживается Presto, Trino, Flink, Hive, Dremio и другие через открытые коннекторы.
- Единый подход к Batch и Streaming: позволяет использовать одни и те же Delta-таблицы как источник или приемник данных как для пакетной, так и для потоковой обработки.

5. Сравнение Data Lake, Data Warehouse и Data Lakehouse

| Критерий            | Data Warehouse (DW)                       | Data Lake (DL)                                  | Data Lakehouse (DLH)                                    |
| : | :- | :- | : |
| Хранилище       | Специализированные системы, БД            | Дешевое файловое/объектное хранилище (HDFS/S3)     | Дешевое файловое объектное хранилище (HDFS/S3)             |
| Типы данных     | Строго структурированные                  | Любые (сырые, структурированные, полу-, неструк.)| Любые (на базе открытых форматов Parquet/ORC)           |
| Схема           | Schema-on-Write (при ETL)      | Schema-on-Read (определяется при чтении)        | Schema-on-Read с управлением и эволюцией схемы (Schema Enforcement/Evolution)|
| Транзакции (ACID)| Да                                        | Нет                                             | Да (через уровень метаданных: Iceberg/Hudi/Delta)        |
| Изменения (CRUD)| Эффективно                                | Сложно (перезапись файлов/партиций)             | Эффективно (Upserts, Deletes через уровень метаданных) |
| Качество данных | Высокое (за счет ETL/валидации)           | Низкое (потенциально "болото")                  | Высокое (за счет управления схемой, транзакций) |
| Производительность| Высокая для BI/SQL       | Низкая для SQL без оптимизаций | Высокая для BI/SQL и ML/DS (за счет оптимизаций) |
| Стоимость       | Высокая (хранение и вычисления)           | Низкая (хранение) + стоимость вычислений        | Низкая (хранение) + оптимизированная стоимость вычислений |
| Гибкость        | Низкая                                    | Высокая                                         | Высокая (хранение любых данных) + Структура (для аналитики) |
| Основные Use Cases| BI, Отчетность, Корпоративная аналитика | Хранение сырых данных, ML/DS, Исследования      | Универсальный: BI, ML/DS, Streaming, Аналитика на одной платформе |
| Технологии      | Teradata, Snowflake, Redshift, BigQuery   | HDFS, S3 + Spark, Hive, Presto             | HDFS, S3 + Iceberg/Hudi/Delta + Spark, Trino etc. |

6. Сравнение Iceberg, Hudi, Delta Lake (Уровень метаданных)

Хотя все три технологии реализуют концепцию Lakehouse и их возможности похожи, у них разные особенности реализации.

| Критерий            | Apache Iceberg                                  | Apache Hudi                                     | Delta Lake                                          |
| : | :- | :- | :-- |
| Основной фокус  | Открытый формат таблицы, спецификация, гибкость в выборе движка.          | Управление данными, инкрементальная обработка, управление изменениями (Upserts/Deletes).  | Надежность, транзакционный лог, экосистема Spark/Databricks, унификация Batch/Streaming.   |
| Механизм метаданных| Снимки (Snapshots) -> Манифесты -> Файлы. Управляется внешним Каталогом.                | Временная шкала (Timeline) коммитов и действий.   | Журнал транзакций (DeltaLog).                        |
| Управление файлами| Управляется движками и процессами на основе спецификации формата.                  | Встроенные процессы для обслуживания (компакция, очистка, кластеризация).         | Встроенные утилиты и команды (OPTIMIZE, VACUUM, ZORDER BY).          |
| Обработка изменений| Реализуется движками поверх формата Iceberg (например, MERGE в Spark). | Встроенные типы таблиц (COW, MOR) и оптимизированные операции Upsert/Delete. | Встроенная мощная команда MERGE INTO.      |
| Управление Схемой| Гибкая эволюция схемы (добавление, удаление, переименование). | Поддерживается эволюция схемы.                  | Schema Enforcement по умолчанию, добавление столбцов.   |
| Партиционирование| Скрытое партиционирование, эволюция партиционирования. | Поддерживается партиционирование.              | Поддерживается партиционирование, Z-ordering.        |
| Экосистема      | Широкая и растущая поддержка множеством движков. | Хорошая поддержка (особенно Spark, Flink). | Сильная интеграция со Spark/Databricks, растет поддержка других. |
| Происхождение   | Netflix                                         | Uber                                            | Databricks                                          |
| Лицензия        | Apache 2.0                                      | Apache 2.0                                      | Apache 2.0 (ядро) + Проприетарное (в платформе Databricks)     |

Все три проекта активно развиваются, и их возможности постоянно расширяются и сближаются. Выбор часто зависит от уже используемых технологий, специфики рабочих нагрузок и предпочтений команды.

Databricks купил компанию Tabular, которая была основана создателями Apache Iceberg (Райаном Блю, Дэниелом Уиксом и Джейсоном Ридом). Цель этой покупки — не заменить Delta Lake на Iceberg, а глубоко интегрировать Iceberg в платформу Databricks и стать лидером в области совместимости форматов данных для Lakehouse. Databricks стремится к тому, чтобы их платформа была лучшим местом для работы с данными в любом открытом формате, будь то Delta Lake, Apache Iceberg или Apache Hudi.

Ключевое различие между Iceberg и Delta Lake лежит в архитектуре управления метаданными. Это фундаментальное отличие порождает все остальные преимущества.

1. Управление метаданными: Иерархическая структура vs. Линейный лог
- Delta Lake: Использует транзакционный лог (_delta_log), который представляет собой упорядоченную последовательность JSON-файлов (и чекпоинтов в формате Parquet). Каждый коммит (добавление, удаление, обновление данных) создает новый JSON-файл. Чтобы получить текущее состояние таблицы, движок (например, Spark) должен просканировать лог, чтобы "накатить" все изменения. На очень больших таблицах с миллионами файлов и долгой историей изменений (тысячи коммитов) этот лог становится узким местом. Планирование запроса требует получения списка и чтения большого количества файлов в логе, что замедляет запуск запросов.
- Apache Iceberg: Использует иерархическую структуру метаданных, напоминающую дерево.
    1.  Файл метаданных (Metadata File): Один metadata.json файл на вершине. Он указывает на текущую схему, спецификацию партиционирования, свойства и, самое главное, на текущий файл списка манифестов.
    2.  Список манифестов (Manifest List): Этот файл содержит список файлов-манифестов. Для каждой партиции в манифесте хранится статистика (min/max значения), что позволяет очень быстро отсекать ненужные партиции на этом уровне.
    3.  Файлы манифестов (Manifest Files): Каждый манифест содержит список файлов данных (.parquet, .orc и т.д.), а также детальную статистику по каждому файлу (min/max значения для каждого столбца, количество строк и т.д.).
  При планировании запроса движку не нужно читать всю историю транзакций. Он читает один metadata.json, переходит к актуальному списку манифестов, отсекает 99% манифестов по статистике партиций, а затем в оставшихся манифестах отсекает ненужные файлы данных по статистике столбцов. Это делает планирование запросов на порядки быстрее для больших таблиц.

2. Скрытое партиционирование (Hidden Partitioning) и Эволюция партиций

Это, возможно, самое сильное преимущество Iceberg для долгосрочного сопровождения данных.

- Delta Lake: Использует физическое партиционирование в стиле Hive. Структура каталогов на диске напрямую отражает партиционирование (например, "year=2023/month=12/day=25/"). Если вы решили изменить схему партиционирования (например, перейти от дневного к часовому или наоборот), вам нужно полностью переписать всю таблицу. Это чрезвычайно дорогая и рискованная операция для таблиц размером в петабайты.

- Iceberg: Партиционирование — это логическая концепция, хранящаяся в метаданных, а не в физической структуре каталогов. Iceberg "скрывает" реальные пути к файлам от пользователя. Вы можете определить партиционирование по столбцу event_ts (timestamp). Iceberg может применять к нему функции трансформации, например, days(event_ts) или hours(event_ts). Эти трансформации хранятся в метаданных.
Вы можете изменить схему партиционирования без перезаписи старых данных! Например, таблица была партиционирована по дням (days(ts)). Вы понимаете, что данных стало слишком много, и хотите перейти на часовое партиционирование (hours(ts)). Вы просто обновляете метаданные таблицы. Все новые данные будут записываться с использованием новой схемы, а старые данные останутся лежать в старой структуре. Iceberg будет корректно читать данные из обеих схем партиционирования. 

3. Эволюция схемы (Schema Evolution)

Оба формата поддерживают эволюцию схемы (добавление, удаление, переименование столбцов), но Iceberg делает это более надежно.
- Delta Lake: Отслеживает столбцы по имени. Это может создать неоднозначность. Если вы удалили столбец user_id (int), а затем добавили новый столбец с тем же именем user_id (string), некоторые движки могут запутаться при чтении старых файлов.
- Apache Iceberg: Каждому столбцу в схеме присваивается уникальный ID. Все операции сопоставления данных и столбцов происходят по этим ID, а не по именам. Это полностью исключает неоднозначность. Удаление и последующее добавление столбца с тем же именем не вызовет проблем, так как у нового столбца будет новый ID. Это делает эволюцию схемы более безопасной и предсказуемой.

4. Экосистемная нейтральность и независимость от движка
- Delta Lake: Хотя формат открыт и является частью Linux Foundation, его исторические корни и основное развитие тесно связаны с Databricks и Apache Spark. Поддержка в других движках (Trino, Flink, Snowflake) появилась позже и иногда отстает от функциональности, доступной в Spark.
- Iceberg: Был создан в Netflix с самого начала с целью быть независимым от движка запросов. Его спецификация четко определена, и он имеет первоклассную поддержку не только в Spark, но и в Trino, Flink, Presto, Snowflake, Google BigQuery и других. Его управление в рамках ASF гарантирует вендор-нейтральность. Iceberg дает свободу выбора инструментов для работы с одними и теми же данными, что является огромным стратегическим плюсом.

5. Режимы записи
- Delta Lake: Merge-on-Read (MOR) с периодическими слияниями. При частых изменениях чтение постпенно деградирует.
- Iceberg: по умолчанию Copy-on-Write (COW).
Когда вы выполняете операцию UPDATE, DELETE или MERGE, Iceberg работает следующим образом:
Iceberg находит все файлы данных (например, Parquet), которые содержат строки, подлежащие изменению или удалению. Он считывает эти файлы, применяет изменения в памяти (обновляет строки или отбрасывает удаленные) и записывает совершенно новые файлы данных. В рамках одной атомарной транзакции Iceberg обновляет метаданные таблицы: он удаляет ссылки на старые, "затронутые" файлы и добавляет ссылки на новые, свежесозданные файлы. Старые файлы помечаются как "осиротевшие" и будут удалены позже процессом сборки мусора (expire_snapshots).
+ Максимальная производительность чтения: Таблица всегда находится в полностью "чистом" состоянии. Нет никаких дельта-файлов или логов, которые нужно было бы объединять во время чтения. Запросы выполняются очень быстро.
+ Простота: Не требует фоновых процессов слияния (compaction).
- Высокая стоимость записи (Write Amplification): Даже для изменения одной строки в файле размером 1 ГБ, весь этот гигабайт нужно будет прочитать и перезаписать. Это делает операции обновления медленными и дорогими по ресурсам (I/O, CPU).

- Iceberg: режим Merge-on-Read (MOR) нужно включать явно. Он спроектирован для сценариев с частыми, потоковыми обновлениями или удалениями. Iceberg записывает изменения в отдельные, небольшие файлы-удаления (delete files) двух видов:
1. Position Deletes: Файл, который хранит точные координаты удаляемых строк: (путь_к_файлу, позиция_строки). При операциях UPDATE или MERGE. Iceberg записывает новую версию строки в новый файл данных (как append), а старую версию помечает на удаление через position delete.
2. Equality Deletes: Файл, который хранит условия для удаления строк по значению: (user_id = 123). Он говорит: "удали все строки в любых файлах данных, где user_id равен 123". Создается при операциях "DELETE FROM table WHERE ...".
+ Очень быстрые записи: Операции `UPDATE`/`DELETE` не требуют перезаписи больших файлов, а лишь дозаписывают небольшие дельта-файлы. Это идеально для стриминга и CDC.
- Снижение производительности чтения: Чтение становится сложнее, так как требует "склеивания" данных из нескольких источников.
- Необходимость слияния: Со временем накапливается много delete-файлов, что сильно замедляет чтение. Нужен регулярный фоновый процесс (compaction), который будет применять эти удаления к основным файлам и создавать новые, "чистые" файлы данных (по сути, выполняя COW в фоновом режиме).

Iceberg позволяет настроить режим для разных операций отдельно, например:
UPDATE делать через MOR, так как они у вас частые.
DELETE делать через COW, так как они у вас редкие и затрагивают целые партиции.

ALTER TABLE my_iceberg_table SET TBLPROPERTIES (
  'write.update.mode'='merge-on-read',
  'write.delete.mode'='copy-on-write',
  'write.merge.mode'='merge-on-read'
);

6. Каталог таблиц
- Delta Lake: достаточно Hive Metastore.
- Iceberg: тоже достаточно Hive Metastore, но есть варианты.
Ключевая задача каталога Iceberg - хранить и атомарно обновлять "указатель" на текущий файл метаданных (metadata.json) для каждой таблицы. Без этой атомарности были бы невозможны ACID-транзакции.

1. Каталоги на основе файловой системы
а) Hadoop Catalog
Использует саму файловую систему (HDFS, S3, ADLS) для хранения указателя. Атомарность достигается за счет операции `rename`, которая в большинстве файловых систем считается атомарной. Для каждой таблицы создается специальная директория `metadata`, где хранится история версий метаданных.
+ Не требует никаких дополнительных сервисов. Идеально для быстрого старта и локального тестирования.
- Требует получения списка файлов, что может быть медленно на облачных хранилищах.
- Атомарность изменений имени файла не всегда гарантируется на 100% во всех объектных хранилищах (особенно в S3 без специальных настроек).
- Небезопасен для одновременной записи из нескольких процессов/кластеров.
- Только для локальной разработки, экспериментов и очень простых single-writer сценариев. Не рекомендуется для производственного использования.

2. Каталоги на основе баз данных
а) Hive Metastore (HMS)
Cамый распространенный и зрелый вариант для производственных систем (on-premise и в облаке).
Использует существующий Hive Metastore. Указатель на текущий файл metadata.json хранится в параметрах таблицы (table properties) в базе данных метастора (например, MySQL или PostgreSQL). Атомарность обеспечивается транзакциями в этой реляционной БД.
+ Зрелость и стабильность Hive Metastore.
+ Почти все движки (Spark, Trino, Flink) умеют "из коробки" работать с HMS.
+ Единая точка для управления метаданными всех таблиц.
- Требует развертывания и поддержки отдельного сервиса (HMS + его БД).
- Может стать узким местом при очень большом количестве таблиц и запросов к метаданным.
- Стандартный выбор для большинства production-систем, особенно если у вас уже есть экосистема Hadoop/Spark.

б) JDBC Catalog
Позволяет использовать любую JDBC-совместимую базу данных (PostgreSQL, MySQL и т.д.) напрямую, без прослойки в виде Hive Metastore. Iceberg сам создает и управляет необходимыми таблицами для хранения указателей на метаданные.
+ Проще, чем HMS: не нужен сам сервис Hive Metastore, достаточно иметь работающую реляционную БД.
+ Наследует все гарантии ACID от используемой базы данных.
- Вы сами отвечаете за доступность и бэкапы базы данных каталога.
Подходит компаниям, у которых уже есть управляемые кластеры реляционных БД и которые не хотят разворачивать Hive Metastore.

3. Специализированные и облачные каталоги
a) REST Catalog
Это не конкретная реализация, а открытый протокол на основе REST API. Любой сервис, реализующий этот API, может выступать в роли каталога Iceberg.
+ Позволяет разным движкам и системам общаться с одним каталогом через стандартизированный API.
+ Можно создать собственную реализацию каталога под свои нужды.
- Требуется сервис, который этот REST API реализует.
Это будущее для построения открытых, не привязанных к вендору платформ. Сервис Tabular (который купил Databricks) как раз предоставляет реализацию REST-каталога.

б) Project Nessie
Это транзакционный каталог с "Git-подобной" семантикой для данных. Он позволяет создавать ветки (branches), теги (tags) и выполнять слияния.
+ Можно создавать ветки для ETL-экспериментов или разработки, не затрагивая production-данные.
+ Можно "затегировать" состояние всего Lakehouse на определенный момент времени.
+ Гарантирует консистентность изменений сразу в нескольких таблицах.
- Требует развертывания и поддержки.
- Требует от команд освоения нового подхода к работе с данными.
Подходит командам, внедряющим Data Mesh, CI/CD для данных, и тем, кому критически важны мульти-табличные транзакции.
