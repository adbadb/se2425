Конспект лекции
Apache Kafka: Введение в распределенную потоковую платформу

## Введение

На прошлых лекциях мы обсуждали архитектуры хранения и обработки больших данных, такие как Data Lake и Data Lakehouse, Spark, Spark Streaming и Flink. Сегодня мы рассмотрим ключевую технологию, которая служит "нервной системой" для таких систем — Apache Kafka. Она отвечает за сбор и доставку потоков данных в реальном времени от сотен источников в централизованное хранилище или к приложениям-обработчикам.

В основе Kafka лежит простая, но мощная концепция — **распределенный, неизменяемый, append-only лог (журнал)**. Представьте себе журнал, в который можно только дописывать новые записи в конец. Этот журнал распределен по нескольким серверам для надежности и производительности, и любая система может читать записи с любого места в этом журнале. Эта фундаментальная идея объясняет, почему Kafka так быстра, надежна и гибка.

### История и ключевые этапы развития

Apache Kafka была создана в LinkedIn в 2010 году на замену крайне ненадежной инфраструктуру асинхронной доставки сообщений на классических очередях. Они то становились недоступны, возвращались в строй через несколько дней и заливали получателей устаревшими данными, то теряли сообщения, то присылали дубли. Изначально Kafka разрабатывалась как система обмена сообщениями для обработки активности пользователей, но быстро превратилась в полноценную потоковую платформу.

## Почему Kafka? Ключевые преимущества

Kafka решает ряд проблем, с которыми сталкиваются современные распределенные системы:

1. **Высокая пропускная способность**: Обработка миллионов сообщений в секунду благодаря последовательной записи/чтению с диска.
2. **Низкая задержка**: Задержка в несколько миллисекунд.
3. **Масштабируемость**: Горизонтальное масштабирование путем простого добавления новых узлов (брокеров).
4. **Отказоустойчивость**: Репликация данных между узлами для защиты от сбоев.
5. **Долговременное хранение**: Сообщения могут храниться днями, месяцами или вечно, что позволяет "перематывать" историю событий.
6. **Экосистема**: Инструменты для решения широкого круга задач (Kafka Connect, ksqlDB, Schema Registry, REST Proxy, librdkafka).

## Основные сценарии использования

1.  **Обмен сообщениями**: Асинхронная коммуникация между микросервисами.
2.  **Отслеживание активности**: Сбор кликстрима, логов действий пользователей.
3.  **Агрегация логов**: Централизованный сбор логов со всех серверов и приложений.
4.  **Обработка потоков данных**: Аналитика, трансформация и обогащение данных в реальном времени.
5.  **Интеграция систем (ETL/ELT)**: Перемещение данных между базами данных, хранилищами и приложениями.
6.  **Event Sourcing**: Использование Kafka как единого источника правды о всех событиях в системе.

## Сравнение с традиционными брокерами сообщений (RabbitMQ, ActiveMQ)

| Характеристика         | Kafka                                                      | Традиционные системы (RabbitMQ и др.)             |
| ---------------------- | ---------------------------------------------------------- | ------------------------------------------------- |
| **Основная идея*-    | Распределенный лог                                         | Очередь сообщений                                 |
| Модель доставки        | Pull-модель (консьюмер запрашивает данные)                 | Push-модель (брокер отправляет данные)            |
| Хранение данных        | **Долговременное**, сообщения не удаляются после прочтения | Обычно **краткосрочное**, удаление после доставки |
| Пропускная способность | **Очень высокая** (миллионы сообщ./сек)                    | Обычно ниже                                       |
| Порядок сообщений      | Гарантирован **в рамках партиции*-                       | Гарантирован в рамках очереди                     |
| Масштабируемость       | Высокая горизонтальная                                     | Часто ограничена возможностями одного узла        |

# Архитектура и основные компоненты Apache Kafka

## Общая архитектура

Kafka — это распределенная система, построенная на модели "публикация-подписка" (publish-subscribe).

**Основные компоненты экосистемы Kafka:**
1.  **Брокеры (Brokers)**: Серверы, формирующие кластер Kafka.
2.  **ZooKeeper / KRaft**: Сервис для координации кластера.
3.  **Продюсеры (Producers)**: Клиенты, публикующие сообщения.
4.  **Консьюмеры (Consumers)**: Клиенты, читающие сообщения.
5.  **Топики (Topics)**, **Партиции (Partitions)** и **Реплики (Replicas)**.
6.  **Kafka Connect**: Фреймворк для интеграции с внешними системами.
7.  **Kafka Streams**: Библиотека для потоковой обработки.
8.  **Schema Registry**: Сервис для управления схемами данных.

## Брокеры, ZooKeeper и KRaft

- **Брокеры** — это серверы, которые хранят данные (партиции топиков) и обслуживают запросы клиентов. Кластер Kafka состоит из нескольких брокеров.
- **ZooKeeper** — исторически использовался для управления кластером: хранения конфигураций, назначений лидеров разделов и их последователей,  отслеживания состояния брокеров.
- **KRaft (Kafka Raft)** — начиная с версии 2.8, Kafka может работать без ZooKeeper, используя протокол консенсуса Raft. Это упрощает архитектуру и повышает производительность. В новых развертываниях рекомендуется использовать KRaft. 

## Топики, партиции и смещения (Offsets)

- **Топик (Topic)** — именованный поток событий. Например, `user-clicks` или `order-updates`.
- **Партиция (Partition)** — топик делится на одну или несколько партиций. Каждая партиция — это упорядоченный, неизменяемый лог. Разделение на партиции позволяет распараллелить запись и чтение, распределив их по разным брокерам.
- **Смещение (Offset)** — это уникальный последовательный номер, который Kafka присваивает каждому сообщению в партиции. Консьюмеры используют offset, чтобы отслеживать, какие сообщения они уже прочитали.

### Стратегии хранения и очистки данных (Retention Policies)
1.  **Удаление по времени/размеру (Delete)**: Самая простая стратегия. Сообщения удаляются, когда они становятся старше определенного времени (`retention.ms`) или когда лог партиции превышает заданный размер (`retention.bytes`).
2.  **Компактификация (Log Compaction)**: Эта стратегия гарантирует, что Kafka сохранит **только последнее сообщение для каждого ключа**. Старые сообщения с тем же ключом удаляются. Идеально подходит для хранения состояний, конфигураций или данных для KTable. Топик при этом может быть бесконечным по времени.

## Репликация и отказоустойчивость

- **Репликация** — это механизм копирования партиций на несколько брокеров для обеспечения отказоустойчивости.
- **Фактор репликации (Replication Factor)** — общее количество копий партиции. Рекомендуемое значение для продакшена — 3.
- **Лидер (Leader)** и **Последователи (Followers)**: Для каждой партиции одна из реплик назначается *лидером*. Все запросы на запись и чтение идут через лидера. Остальные реплики — *последователи* — активно копируют данные с лидера. Обратите внимание, то реплики сами регулярно обращаются к лидеру и выкачивают накопившиеся сообщения. Лидер никогда по собственной инициативе к своим последователям не обращается. 
- **In-Sync Replicas (ISR)** — это набор реплик (включая лидера), которые не сильно отстают от лидера. Отставание определяется параметром `replica.lag.time.max.ms` (по умолчанию - 30 секунд). Только реплика из ISR может стать новым лидером в случае сбоя текущего. Лидер всегда входит в ISR.
- **`min.insync.replicas`**: Настройка, определяющая минимальное количество реплик из ISR, которые должны подтвердить запись, чтобы она считалась успешной. Если `min.insync.replicas=2` и `acks=all`, продюсер получит подтверждение, только когда лидер и хотя бы один последователь запишут сообщение. Это защищает от потери данных.

## Kafka Connect: Интеграция без кода

**Kafka Connect** — это фреймворк для надежной и масштабируемой потоковой передачи данных между Kafka и другими системами. Он избавляет от необходимости писать кастомный код для интеграций.

- **Source-коннекторы**: Читают данные из внешних систем (например, из базы данных PostgreSQL, S3) и отправляют их в Kafka.
- **Sink-коннекторы**: Читают данные из Kafka и записывают их во внешние системы (например, в Elasticsearch, BigQuery).

Существуют сотни готовых коннекторов, что делает Kafka Connect мощнейшим инструментом для построения data pipelines.

## Schema Registry: Гарантия контракта данных

**Schema Registry** — это **критически важный** компонент для промышленных систем на Kafka. Это централизованный сервис для управления схемами данных (Avro, Protobuf, JSON Schema).

### Зачем нужен Schema Registry?
1.  **Гарантия контракта данных**: Продюсер не сможет отправить данные, не соответствующие схеме. Консьюмер всегда знает, в каком формате придут данные. Это предотвращает ошибки парсинга и хаос в данных.
2.  **Эффективная сериализация**: При использовании форматов вроде Avro или Protobuf, в топик отправляется не громоздкий JSON, а компактный бинарный payload и маленький ID схемы. Это экономит место на диске и сетевой трафик.
3.  **Эволюция схем**: Позволяет безопасно изменять схему (например, добавлять новое опциональное поле), проверяя совместимость (обратную, прямую, полную). Старые консьюмеры не сломаются при обновлении схемы продюсером.

# Продюсеры и консьюмеры

## Продюсеры (Producers)
Продюсеры отправляют сообщения в топики.

- **Партиционирование**: Продюсер решает, в какую партицию топика отправить сообщение.
    - **По ключу (Key-based)**: Сообщения с одинаковым ключом всегда попадают в одну и ту же партицию. **Это гарантирует порядок обработки для данного ключа.**
    - **Случайно (Sticky batching)**: Если ключ не указан, сообщения распределяются по партициям случайно (но пакетами) для балансировки нагрузки.
- **Пакетная отправка (Batching)**: Для эффективности продюсер накапливает сообщения в буфере (`batch.size`, `linger.ms`) и отправляет их пакетами.
- **Сжатие (Compression)**: Поддержка сжатия (snappy, lz4, gzip, zstd) для уменьшения сетевого трафика.
- **Подтверждение (`acks`)**: Настройка, определяющая уровень надежности отправки - количество подтверждений, которые продюсер хочет получить.

### Пример кода продюсера на Python (асинхронный)
```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
    key_serializer=lambda k: k.encode('utf-8'),
    acks='all'
)

futures = []
for i in range(10):
    key = f"user-{i % 2}"  # Два разных ключа для демонстрации
    value = {"id": i, "message": f"value-{i}"}
    
    # Асинхронная отправка. Метод send() возвращает объект Future.
    future = producer.send('my-topic', key=key, value=value)
    futures.append(future)

# Дожидаемся отправки всех сообщений в пакете
for future in futures:
    try:
        record_metadata = future.get(timeout=10)
        print(f"Message sent to topic {record_metadata.topic}, partition {record_metadata.partition}")
    except Exception as e:
        print(f"Error sending message: {e}")

producer.flush() # Гарантирует отправку всех оставшихся сообщений
producer.close()
```

## Консьюмеры и группы консьюмеров
Консьюмеры читают сообщения из топиков.

- **Pull-модель**: Консьюмер сам запрашивает (pull) данные у брокера, что позволяет ему контролировать темп обработки.
- **Группы консьюмеров (Consumer Groups)**:
    - Несколько консьюмеров могут объединиться в группу (установить одинаковое значение `group.id`), чтобы совместно читать из одного топика.
    - Kafka **гарантирует, что каждая партиция топика будет назначена только одному консьюмеру в рамках группы**.
    - Это основной механизм масштабирования чтения. Если в топике 4 партиции, можно запустить до 4 консьюмеров в группе для параллельной обработки. Пятый и все последующие консьюмеры будут простаивать.
- **Управление смещением (Offset Management)**: Консьюмер должен "коммитить" (сохранять) смещение последнего обработанного сообщения. Смещения хранятся в специальном топике `__consumer_offsets`.
    - **Автоматический коммит (`enable.auto.commit=true`)**: Просто, но рискованно. Может привести к потере или дублированию сообщений при сбое.
    - **Ручной коммит (`enable.auto.commit=false`)**: Надежно. Контроль полностью в руках разработчика. Вы коммитите смещение после успешной обработки сообщения.

### Перебалансировка потребителей (Consumer Rebalancing)
Когда консьюмер присоединяется к группе или покидает ее (из-за сбоя или штатного выключения), Kafka выполняет  **перебалансировку группы**, чтобы перераспределить партиции между активными членами группы.

- **Старый протокол ("Eager Rebalancing")**: Приводил к остановке всех консьюмеров в группе на время перебалансировки ("stop-the-world").
- **Новый протокол ("Cooperative Rebalancing", с Kafka 2.4+)**: Позволяет другим консьюмерам продолжать обрабатывать свои партиции, пока новые партиции назначаются прибывшему/перераспределяются с ушедшего. Это значительно снижает время простоя.

# Гарантии доставки сообщений

### 1. At-most-once (максимум один раз)
Сообщения могут быть потеряны, но никогда не дублируются.
- **Продюсер**: `acks=0` (отправил и забыл).
- **Консьюмер**: Коммитит смещение *до* обработки сообщения.
- **Применение**: Некритичные метрики, где потеря данных допустима.

### 2. At-least-once (как минимум один раз)
Сообщения никогда не теряются, но могут дублироваться. Это **настройка по умолчанию** и самый частый сценарий.
- **Продюсер**: `acks=all` (или `1`), `retries > 0`.
- **Консьюмер**: Коммитит смещение *после* обработки сообщения. При сбое до коммита, сообщение будет прочитано повторно.
- **Применение**: Большинство систем, где потеря данных недопустима, а с дубликатами можно бороться (например, идемпотентной обработкой).

### 3. Exactly-once (ровно один раз)
Сообщения доставляются ровно один раз. Достигается с помощью идемпотентности и транзакций (и только с помощью консьюмера).

#### Идемпотентные продюсеры
Включается настройкой `enable.idempotence=true`. Продюсер присваивает сообщениям уникальный порядковый номер, и брокер отбрасывает дубликаты, которые могут возникнуть при повторных отправках (retries).

Ключевое преимущество: позволяет безопасно установить `max.in.flight.requests.per.connection` > 1 (до 5), что значительно повышает пропускную способность продюсера без риска нарушения порядка сообщений.

#### Транзакции
Транзакции позволяют атомарно записывать сообщения в несколько партиций и топиков.
```java
// Продюсер
props.put("transactional.id", "my-transactional-id");
producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(record1);
    producer.send(record2);
    producer.commitTransaction();
} catch (Exception e) {
    producer.abortTransaction();
}

// Консьюмер должен читать только закоммиченные сообщения
// Если это значение не установлено, консьюмер получит все сообщения, в том числе и не закоммиченные props.put("isolation.level", "read_committed");
```

#### Exactly-Once в потоковой обработке (Consume-Process-Produce)
Для полного цикла "чтение-обработка-запись" Kafka обеспечивает EOS, позволяя коммитить смещения консьюмера **в рамках той же транзакции**, в которой продюсер записывает результат. Это гарантирует, что и чтение, и запись произойдут атомарно как единое целое.

```java
// Логика внутри транзакции
producer.beginTransaction();
// 1. Отправка обработанных сообщений
producer.send(outputRecord1);
producer.send(outputRecord2);
// 2. Коммит смещений прочитанных сообщений в той же транзакции
producer.sendOffsetsToTransaction(consumerOffsets, consumer.groupMetadata());
producer.commitTransaction();
```

# Kafka Streams и ksqlDB: Потоковая обработка

## Kafka Streams
Это **клиентская библиотека** для Java/Scala, которая позволяет вашему приложению обрабатывать потоки данных. Она не требует отдельного кластера — логика обработки выполняется прямо в вашем приложении.

- **Ключевые концепции**:
    - **KStream**: Поток независимых событий (например, клики).
    - **KTable**: Поток изменений состояния, представляет собой таблицу, где каждый ключ имеет текущее значение (например, профили пользователей).
    - **Топология**: Граф обработки (источник -> трансформация -> приемник).
- **Особенности**:
    - Обработка с состоянием (Stateful) с хранением состояния в локальном RocksDB и резервированием в Kafka.
    - Поддержка оконных операций (Tumbling, Hopping, Session windows).
    - Встроенная поддержка семантики Exactly-Once.

### Пример: WordCount на Kafka Streams
```java
// Создание топологии обработки
StreamsBuilder builder = new StreamsBuilder();
// 1. Читаем из входного топика как KStream
KStream<String, String> textLines = builder.stream("text-lines");

// 2. Обрабатываем данные
KTable<String, Long> wordCounts = textLines
    .flatMapValues(value -> Arrays.asList(value.toLowerCase().split("\\W+")))
    .groupBy((key, word) -> word)
    .count(); // Агрегируем и создаем KTable

// 3. Записываем результат в выходной топик
wordCounts.toStream().to("word-counts", Produced.with(Serdes.String(), Serdes.Long()));

// Запускаем приложение
KafkaStreams streams = new KafkaStreams(builder.build(), props);
streams.start();
```

## ksqlDB
**ksqlDB** — это база данных для потоковой обработки, которая позволяет работать с данными в Kafka с помощью знакомого **SQL-синтаксиса**. Она работает поверх Kafka Streams, но скрывает сложность программирования.

- **STREAM**: Аналог KStream, неограниченный поток событий.
- **TABLE**: Аналог KTable, изменяемая коллекция данных.
- **Запросы**: Могут быть как постоянными (создают новый поток/таблицу), так и непостоянными (возвращают результат на момент запроса).

### Пример: Фильтрация и агрегация на ksqlDB
```sql
-- 1. Создаем поток на основе существующего топика
CREATE STREAM pageviews (viewtime BIGINT, userid VARCHAR, pageid VARCHAR)
    WITH (KAFKA_TOPIC='pageviews-topic', VALUE_FORMAT='JSON');

-- 2. Создаем новый поток, отфильтровав данные (постоянный запрос)
CREATE STREAM pageviews_important AS
    SELECT * FROM pageviews WHERE pageid = 'home';

-- 3. Создаем таблицу с агрегированными данными (подсчет просмотров по пользователям)
CREATE TABLE user_page_counts AS
    SELECT userid, COUNT(*) as view_count FROM pageviews_important
    GROUP BY userid;
```

### Kafka Streams vs. ksqlDB

| Характеристика    | Kafka Streams                                  | ksqlDB                                                           |
| ----------------- | ---------------------------------------------- | ---------------------------------------------------------------- |
| **Интерфейс*-   | Java/Scala API                                 | SQL                                                              |
| **Гибкость*-    | **Максимальная**. Полный контроль над логикой. | **Ограничена** возможностями SQL.                                |
| **Сложность*-   | Требует навыков программирования.              | **Низкая**. Идеально для аналитиков и быстрого прототипирования. |
| **Развертывание** | Как часть вашего приложения.                   | Требует отдельного ksqlDB-сервера.                               |

**Используйте Kafka Streams**, когда нужна сложная бизнес-логика, интеграция с внешними системами или полный контроль.
**Используйте ksqlDB**, когда нужно быстро выполнять фильтрацию, обогащение, агрегацию данных, и когда команда хорошо владеет SQL.