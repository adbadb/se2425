Семинар
Введение в Apache Flink для Обработки Потоковых Данных

**Цель Занятия:** Получить практический опыт работы с Apache Flink, научиться создавать потоковые приложения, использовать Keyed State и оконные функции, а также понять механизмы времени и отказоустойчивости на практике.

**Требования:**
- Установленная среда разработки (IDE) с поддержкой Maven или Gradle.
- Docker и Docker Compose (для локальной установки Flink).
- Понимание концепций, изложенных в лекции по Flink.

**План Занятия:**

1.  **Настройка Среды (Демонстрация)**
    - Быстрый обзор Docker Compose файла для запуска Flink кластера (JobManager + TaskManager).
    - Запуск Flink кластера.
    - Обзор Flink Web UI.
    - Создание базового Maven/Gradle проекта с необходимыми Flink зависимостями.
    - Запуск простейшей "Hello World" Flink job (например, чтение из сокета, печать).
	
2.  **Задание 1: Базовая Потоковая Трансформация (Самостоятельная работа)**
    - Чтение данных из источника (сокет).
    - Применение простых преобразований (`map`, `filter`).
    - Вывод результата.
	
3.  **Задание 2: Keyed Stream и Keyed State (Самостоятельная работа)**
    - Чтение структурированных данных.
    - Использование `keyBy()`.
    - Поддержание и обновление Keyed State (`ValueState`).
	
4.  **Задание 3: Оконная Агрегация с Event Time и Watermarks (Самостоятельная работа)**
    - Чтение данных с метками времени Event Time.
    - Назначение Watermarks.
    - Применение окон с Event Time (`TumblingEventTimeWindows`).
    - Выполнение агрегации в окне.
    - (Демонстрация) Наблюдение за Watermarks и окнами в Web UI.
	
5.  **Задание 4: Отказоустойчивость (Демонстрация)**
    - Запуск stateful job (из Задания 2 или 3) с включенным Checkpointing.
    - Наблюдение за созданием чекпоинтов в Web UI.
    - Имитация сбоя (остановка TaskManager).
    - Наблюдение за восстановлением job из чекпоинта.
	
6.  **Задание 5 (Опционально / Для продвинутых): Использование ProcessFunction и Таймеров (Самостоятельная работа)**
    - Использование низкоуровневого `ProcessFunction`.
    - Работа с Event Time и Process Time таймерами.
    - Более тонкое управление состоянием и событиями.

**Детальное Описание Заданий**

**1. Настройка Среды (Демонстрация Преподавателем)**

- **Цель:** Обеспечить всех студентов работающей средой для разработки и выполнения Flink job.
- **Действия Преподавателя:**
    - Показать `docker-compose.yml` файл с минимальной конфигурацией Flink (JobManager, TaskManager). Объяснить роли компонентов. Пример:
        ```yaml
        version: "3"
        services:
          jobmanager:
            image: apache/flink:1.17
            ports:
              - "8081:8081" # Flink Web UI
            command: jobmanager
            environment:
              - |
                FLINK_PROPERTIES=
                jobmanager.rpc.address: jobmanager
                state.checkpoints.dir: file:///checkpoints # Для демонстрации чекпоинтов
                state.backend: filesystem # Для демонстрации чекпоинтов
                state.backend.fs.checkpointdir: file:///checkpoints # Для демонстрации чекпоинтов

          taskmanager:
            image: apache/flink:1.17
            depends_on:
              - jobmanager
            command: taskmanager
            environment:
              - |
                FLINK_PROPERTIES=
                jobmanager.rpc.address: jobmanager
                taskmanager.numberOfTaskSlots: 2 # Количество параллельных слотов
            volumes:
              - /tmp/checkpoints:/checkpoints # Маппинг для доступа к чекпоинтам (опционально)
        ```
    - Запустить `docker-compose up -d`.
    - Открыть Flink Web UI по адресу `localhost:8081`. Показать разделы "Task Managers", "Jobs".
    - Создать простой Maven или Gradle проект. Добавить зависимости `flink-streaming-java`, `flink-clients`. (Можно использовать Maven archetype `flink-quickstart-java` или `flink-quickstart-scala`).
    - Написать и запустить простейшую job:
        ```java
        import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
        import org.apache.flink.streaming.api.datastream.DataStream;

        public class SimpleJob {
            public static void main(String[] args) throws Exception {
                // Настройка среды выполнения
                StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

                // Источник данных: чтение строк из TCP-сокета
                DataStream<String> text = env.socketTextStream("localhost", 9999);

                // Простая трансформация (например, добавить префикс)
                DataStream<String> processed = text.map(value -> "Received: " + value);

                // Приемник данных: вывод в стандартный вывод TaskManager'а
                processed.print();

                // Запуск job
                env.execute("Socket Reader");
            }
        }
        ```
    - Показать, как скомпилировать проект (`mvn clean package`) и отправить JAR на Flink кластер через Web UI или командную строку (`flink run -c your.package.SimpleJob target/your-job.jar`).
    - Запустить netcat (`nc -lk 9999`) и показать, как ввод текста в netcat приводит к выводу в логах TaskManager'а.

- **Студенты:** Устанавливают Docker, клонируют репозиторий с примерами или создают свой проект, убеждаются, что могут запустить предоставленный базовый пример.

**2. Задание 1: Базовая Потоковая Трансформация (Самостоятельная Работа)**

- **Цель:** Закрепить навыки создания и запуска Flink job, работы с базовыми преобразованиями.
- **Описание:**
    1.  Взять за основу код из демонстрации (чтение из сокета).
    2.  Изменить трансформацию:
        - Преобразовать все входящие строки в нижний регистр.
        - Отфильтровать строки, которые не содержат букву 'a'.
    3.  Вывести результат.
    4.  Собрать и запустить job на Flink кластере.
    5.  Используя `nc -lk 9999`, отправить несколько тестовых строк (с 'a', без 'a', с заглавными).
    6.  Проверить логи TaskManager'а, чтобы убедиться, что фильтрация и преобразование в нижний регистр работают корректно.

- **Ожидаемый Результат/Подсказки:**
    - Используйте `.map(String::toLowerCase)` или `.map(value -> value.toLowerCase())`.
    - Используйте `.filter(value -> value.contains("a"))`.
    - Если ввести "Apple", в логах TaskManager'а должно появиться "apple".
    - Если ввести "Banana", в логах TaskManager'а ничего не должно появиться.
    - Если ввести "Orange", в логах TaskManager'а должно появиться "orange".

**3. Задание 2: Keyed Stream и Keyed State (Самостоятельная Работа)**

- **Цель:** Научиться партиционировать поток по ключу и использовать Keyed State для поддержания агрегированного значения для каждого ключа.
- **Описание:**
    1.  Создать новую Flink job.
    2.  Источник данных: чтение строк из сокета в формате "ключ,значение" (например, "sensor1,10", "sensor2,15", "sensor1,12").
    3.  Парсить входные строки в пары (String ключ, Integer значение).
    4.  Использовать `keyBy()` по полю "ключ".
    5.  Применить `RichMapFunction` (или `ProcessFunction`) для:
        - Доступа к Keyed State типа `ValueState<Integer>` для каждого ключа.
        - При получении нового значения для ключа, прочитать текущее состояние, прибавить новое значение и обновить состояние.
        - Вывести в консоль пару (ключ, текущая_сумма).
    6.  Собрать, запустить job и протестировать, отправляя данные для разных ключей.

- **Ожидаемый Результат/Подсказки:**
    - Создайте класс, наследующий `RichMapFunction<String, Tuple2<String, Integer>>` (вход строка, выход пара ключ-сумма). В `open()` инициализируйте `ValueStateDescriptor`. В `map()` используйте `getRuntimeContext().getState(...)`, прочитайте, обновите и запишите состояние, верните новую пару.
    - Используйте `.map(line -> { String[] parts = line.split(","); return new Tuple2<>(parts[0], Integer.parseInt(parts[1])); })` для парсинга.
    - Используйте `.keyBy(0)` или `.keyBy(tuple -> tuple.f0)`.
    - Для ввода: `echo "sensor1,10" | nc -N localhost 9999`, затем `echo "sensor2,15" | nc -N localhost 9999`, затем `echo "sensor1,12" | nc -N localhost 9999`.
    - Вывод в логах TaskManager'а должен быть примерно таким:
        `... (sensor1,10)`
        `... (sensor2,15)`
        `... (sensor1,22)`
        (Порядок строк может отличаться для разных ключей, но для одного ключа сумма должна быть последовательной).

**4. Задание 3: Оконная Агрегация с Event Time и Watermarks (Самостоятельная Работа и Демонстрация)**

- **Цель:** Научиться работать с Event Time, Watermarks и применять оконные функции для агрегации событий в заданных временных интервалах.
- **Описание:**
    1. Создать новую Flink job.
    2. Источник данных: чтение строк из сокета в формате "timestamp,ключ" (например, "1678886400000,A", "1678886401500,B", "1678886402800,A", "1678886406000,A"). Timestamp в миллисекундах (Event Time).
    3. Парсить входные строки в пары (Long timestamp, String ключ).
    4. **ВАЖНО:** Назначить Event Time для каждого события и настроить генерацию Watermarks. Использовать `BoundedOutOfOrdernessTimestampExtractor` с задержкой 1 секунда (`Time.seconds(1)`).
    5. Использовать `keyBy()` по полю "ключ".
    6. Применить **Tumbling Event Time Window** размером 5 секунд (`Time.seconds(5)`).
    7. В каждом окне подсчитать количество событий для каждого ключа (`.count()`).
    8. Вывести результат (например, "Window \[start, end) for key X: count Y").
    9. Собрать и запустить job.
    10. Используя `nc -lk 9999`, отправить данные с возрастающими timestamp (имитируя поток). Включить несколько событий с немного более ранним timestamp, чем предыдущие (имитируя out-of-order).
    11. Наблюдать за выводом.

- **Ожидаемый Результат/Подсказки:**
    - Парсинг: `Tuple2<Long, String>`.
    - `assignTimestampsAndWatermarks`: потребует реализации `extractTimestamp`.
    - `keyBy(1)` или по полю ключа.
    - `window(TumblingEventTimeWindows.of(Time.seconds(5)))`.
    - `.count()` после `.window()`.
    - Вывод будет появляться *не сразу* после отправки данных, а только когда Watermark "пройдет" конец окна. Например, для окна \[1678886400000, 1678886405000), результат появится, когда Watermark достигнет или превысит 1678886405000 (плюс задержка Watermark).
    - Отправьте:
        `1678886400000,A`
        `1678886401000,B`
        `1678886402000,A`
        `1678886404000,A`
        `1678886406000,B` (Это событие попадет в следующее окно \[1678886405000, 1678886410000))
        `1678886403000,A` (Out-of-order, должно попасть в первое окно, если Watermark еще не прошел 1678886405000 + задержка)
        `1678886407000,B`
        `1678886411000,A` (Это событие "продвинет" Watermark достаточно, чтобы закрыть первое и второе окно)
    - Ожидаемый вывод (может отличаться порядок окон):
        `... (A,3)` (для окна \[1678886400000, 1678886405000))
        `... (B,2)` (для окна \[1678886405000, 1678886410000))
        (Событие `1678886403000,A` должно быть включено в первое окно).

- **Демонстрация Преподавателем:**
    - Показать в Web UI вкладку "Job Graph". Объяснить, как выглядит граф job с источником, Watermark Assigner, KeyBy, Window, Aggregate, Sink.
    - Показать вкладку "Watermarks" для работающей job, чтобы студенты увидели, как Watermarks продвигаются по операторам. Объяснить, как Watermark сдвигает "границу завершенности" Event Time.

**5. Задание 4: Отказоустойчивость (Демонстрация Преподавателем)**

- **Цель:** Наглядно показать, как Flink использует Checkpointing для восстановления состояния после сбоя.
- **Действия Преподавателя:**
    - Взять job из Задания 2 (счетчик с Keyed State), так как она хорошо демонстрирует сохранение состояния.
    - Остановить запущенную job.
    - Включить Checkpointing в коде job:
        ```java
        env.enableCheckpointing(5000); // Чекпоинт каждые 5 секунд
        env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE); // Гарантия Exactly-once
        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(1000); // Минимум 1 секунда между чекпоинтами
        env.getCheckpointConfig().setCheckpointTimeout(60000); // Таймаут 1 минута
        env.getCheckpointConfig().setMaxConcurrentCheckpoints(1); // Один чекпоинт за раз
        env.getCheckpointConfig().setExternalizedCheckpointCleanup(ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION); // Сохранять при отмене вручную
        ```
    - Убедиться, что в `docker-compose.yml` настроен State Backend (filesystem) и директория для чекпоинтов видна TaskManager'у.
    - Запустить job с включенным Checkpointing.
    - В Web UI показать вкладку "Checkpoints". Объяснить статусы (In Progress, Completed).
    - Отправить немного данных в сокет, чтобы состояние job обновилось и были созданы чекпоинты.
    - Имитировать сбой TaskManager'а: найти id контейнера TaskManager (`docker ps`) и остановить его (`docker stop <container_id>`).
    - В Web UI показать, что TaskManager перешел в статус "Unavailable".
    - Показать, как Flink автоматически перезапускает TaskManager (Docker Compose должен быть настроен на `restart: always` или запущен в режиме, где он сам перезапустит контейнер).
    - После перезапуска TaskManager'а, показать, что job автоматически восстановилась и продолжила работу.
    - Отправить еще данных для тех же ключей, что и до сбоя. Показать, что счетчики продолжили расти с того значения, которое было сохранено в последнем успешном чекпоинте.
    - Объяснить концепцию Savepoints как мануальных чекпоинтов для планового обновления/миграции job. (Можно показать команду `flink savepoint <jobId> /savepoints/my-savepoint`).

**6. Задание 5 (Опционально / Для продвинутых): Использование ProcessFunction и Таймеров (Самостоятельная Работа)**

- **Цель:** Получить опыт работы с низкоуровневым API, который дает полный контроль над состоянием и временем.
- **Описание:**
    1.  Создать новую Flink job.
    2.  Источник данных: чтение строк из сокета в формате "timestamp,userId,eventType" (например, "1678886400000,user1,login", "1678886410000,user2,login", "1678886415000,user1,logout", "1678886430000,user2,logout"). Timestamp в миллисекундах (Event Time).
    3.  Парсить входные строки в POJO класс (например, `LoginEvent { long timestamp; String userId; String eventType; }`).
    4.  Назначить Event Time и настроить генерацию Watermarks (например, `BoundedOutOfOrdernessTimestampExtractor`).
    5.  Использовать `keyBy()` по полю `userId`.
    6.  Применить `KeyedProcessFunction<String, LoginEvent, String>` (ключ - userId, вход - LoginEvent, выход - String сообщение).
    7.  В `KeyedProcessFunction`:
        - Поддерживать Keyed State (`ValueState<Long>`) для хранения Event Time последнего события `login` для данного пользователя.
        - При получении события `login`: сохранить его Event Time в состояние и установить *Event Time таймер* на 20 секунд *после* времени логина.
        - При получении события `logout`: удалить состояние логина (если оно есть) и отменить установленный таймер (нужно будет сохранить время установленного таймера в другом состоянии).
        - Реализовать метод `onTimer()`: если срабатывает таймер и состояние логина все еще существует (т.е., logout не было), это означает, что пользователь оставался залогиненным более 20 секунд. Вывести сообщение типа "Пользователь [userId] залогинен с [login_timestamp] более 20 секунд.". Очистить состояние логина после вывода сообщения.
    8.  Собрать, запустить job и протестировать, отправляя разные последовательности событий login/logout.

- **Ожидаемый Результат/Подсказки:**
    - В `processElement`: используйте `ctx.timerService().registerEventTimeTimer(event.timestamp + 20000L)`. Чтобы отменить таймер, вам нужно сохранить время установленного таймера (например, в `ValueState<Long> timerTimestamp`) и использовать `ctx.timerService().deleteEventTimeTimer(timerTimestamp.value())`.
    - В `onTimer`: используйте `valueState.value()` для проверки наличия состояния логина.
    - Отправьте данные, которые вызовут срабатывание таймера (login без последующего logout в течение 20 секунд Event Time).
        `1678886400000,user1,login`
        `1678886405000,user2,login`
        `1678886410000,user1,logout` (логин user1 не вызовет таймер, так как logout был раньше)
        `1678886426000,user2,some_event` (Это событие может продвинуть Watermark, вызовет срабатывание таймера для user2, так как 1678886405000 + 20000 = 1678886425000)
        `1678886430000,user3,login`
        ...
    - Ожидаемый вывод: сообщение о пользователе user2.

---

**Общие Рекомендации для Студентов:**

- Внимательно читайте документацию Flink API.
- Используйте Flink Web UI для мониторинга ваших job, просмотра графа, метрик и состояния чекпоинтов.
- Начинайте с малого, постепенно добавляя функциональность.
- При возникновении проблем смотрите логи TaskManager'ов.
- Не забывайте вызывать `env.execute(...)` в конце вашей функции `main`.

**Что Дальше?**

После выполнения этих заданий студенты могут самостоятельно изучить:

- Различные типы окон (Sliding, Session).
- Другие типы агрегаций (ReduceFunction, AggregateFunction).
- Использование `ProcessWindowFunction` для более гибкой обработки результатов окна.
- Интеграцию с реальными источниками и приемниками (Kafka, Elasticsearch, базы данных).
- Flink Table API & SQL API.
- Различные State Backends.

